{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EetdggA0n1pK"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary packages\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import dlib\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import distance as dist\n",
        "from imutils.video import VideoStream\n",
        "from imutils import face_utils\n",
        "from threading import Thread \n",
        "import time\n",
        "import argparse\n",
        "import playsound\n",
        "import imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "from playsound import playsound\n",
        "\n",
        "p = multiprocessing.Process(target=playsound, args=(\"beep.wav\",))\n",
        "p.start()\n",
        "input(\"press ENTER to stop playback\")\n",
        "p.terminate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ys04YtGSqgmK"
      },
      "outputs": [],
      "source": [
        "#plays Alarm sound\n",
        "def alarm():\n",
        "  playsound(\"beep.wav\")\n",
        "\n",
        "def EAR(eye):\n",
        "  a=np.linalg.norm(eye[1]-eye[5])\n",
        "  b=np.linalg.norm(eye[2]-eye[4])\n",
        "  c=np.linalg.norm(eye[0]-eye[3])\n",
        "\n",
        "  ear=(a+b)/(2*c)\n",
        "  return ear\n",
        "\n",
        "def MAR(mouth):\n",
        "  h1=np.linalg.norm(mouth[13]-mouth[19])\n",
        "  h2=np.linalg.norm(mouth[14]-mouth[18])\n",
        "  h3=np.linalg.norm(mouth[15]-mouth[17])\n",
        "  w=np.linalg.norm(mouth[12]-mouth[16])\n",
        "  mar=(h1+h2+h3)/(3*w)\n",
        "  \n",
        "  return mar\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQvaGvN9xH1e",
        "outputId": "1c390204-f02b-486c-fdb3-b629a79b8bc5"
      },
      "outputs": [],
      "source": [
        "# #%%writefile parsing.py\n",
        "# parser=argparse.ArgumentParser()\n",
        "# parser.add_argument(\"-p\", '--shape predictor', required=True, help=\"path to facial landmark predictor\")\n",
        "# parser.add_argument(\"-a\", \"--alarm\", type=str, default=\"\",help=\"path alarm .WAV file\")\n",
        "# parser.add_argument(\"-w\", \"--webcam\", type=int, default=0,help=\"index of webcam on system\")\n",
        "# args = vars(parser.parse_args())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TnXAtJA6yZg-"
      },
      "outputs": [],
      "source": [
        "#Eye\n",
        "EAR_threshold=.32\n",
        "frames_threshold=20\n",
        "\n",
        "#Mouth\n",
        "MAR_threshold=.15\n",
        "Mouth_frames_threshold=20\n",
        "\n",
        "COUNTER=0\n",
        "COUNTER_yawn=0\n",
        "alarm_status=False\n",
        "alarm_status_yawn=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jDpgu8lPyrSh"
      },
      "outputs": [],
      "source": [
        "#Initialising the Dlib's face detector (which is based on HOG)\n",
        "landmark_det=dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TA7VsfYjs1eF"
      },
      "outputs": [],
      "source": [
        "(left_eye_start, left_eye_end)=face_utils.FACIAL_LANDMARKS_IDXS['left_eye']\n",
        "(right_eye_start, right_eye_end)=face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "(mouth_start, mouth_end)=face_utils.FACIAL_LANDMARKS_IDXS['mouth']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "photo=cv.imread('PA030984.JPG.jpg')\n",
        "gray = cv.cvtColor(photo, cv.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "photo=imutils.resize(photo, width=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "rects=landmark_det(photo, 1)\n",
        "my_shape = predictor(gray, rects[0])\n",
        "my_shape = face_utils.shape_to_np(my_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "My_mouth=my_shape[mouth_start: mouth_end]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[244, 113],\n",
              "       [249, 110],\n",
              "       [254, 109],\n",
              "       [258, 110],\n",
              "       [261, 109],\n",
              "       [266, 110],\n",
              "       [271, 112]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "My_mouth[0:7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'landmarks_pos' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-37-0e99ca604f61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstartX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconvert_and_trim_bb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphoto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlandmarks_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;31m#cv.rectangle(gray,r.left(),r.top(), r.right(), r.top(), r.bottom() )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'landmarks_pos' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "def convert_and_trim_bb(image, rect):\n",
        "\t# extract the starting and ending (x, y)-coordinates of the\n",
        "\t# bounding box\n",
        "\tstartX = rect.left()\n",
        "\tstartY = rect.top()\n",
        "\tendX = rect.right()\n",
        "\tendY = rect.bottom()\n",
        "\t# ensure the bounding box coordinates fall within the spatial\n",
        "\t# dimensions of the image\n",
        "\tstartX = max(0, startX)\n",
        "\tstartY = max(0, startY)\n",
        "\tendX = min(endX, image.shape[1])\n",
        "\tendY = min(endY, image.shape[0])\n",
        "\t# compute the width and height of the bounding box\n",
        "\tw = endX - startX\n",
        "\th = endY - startY\n",
        "\t# return our bounding box coordinates\n",
        "\treturn (startX, startY, w, h)\n",
        "\n",
        "boxes = [convert_and_trim_bb(photo, r) for r in landmarks_pos]\n",
        "#cv.rectangle(gray,r.left(),r.top(), r.right(), r.top(), r.bottom() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(221, 61, 72, 72)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for (x, y, w, h) in boxes:\n",
        "\t# draw the bounding box on our image\n",
        "\tcv.rectangle(photo, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "cv.imshow(\"Output\", photo)\n",
        "cv.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rectangle(221,61,293,133)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dlib.rectangle(rect[0].left(), rect[0].top(), rect[0].right(),rect[0].bottom())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "cap=cv.VideoCapture(0)\n",
        "while True:\n",
        "\tret, frame=cap.read()\n",
        "\tframe = imutils.resize(frame, width=600)\n",
        "\tgray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "\trects = landmark_det(frame, 1)\n",
        "\tfor rect in rects:\n",
        "\t\t# determine the facial landmarks for the face region, then\n",
        "\t\t# convert the facial landmark (x, y)-coordinates to a NumPy\n",
        "\t\t# array\n",
        "\t\t#face_rectangle = dlib.rectangle(rect.left(), rect.top(), rect.right(),rect.bottom())\n",
        "\t\tcv.rectangle(frame, (rect.left(), rect.top()), (rect.right(),rect.bottom()), (0,0,255),2)\n",
        "\t\tcv.putText(frame, \"Hiii!\", (rect.left() - 10, rect.top() - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\t\tmy_shape = predictor(gray, rect)\n",
        "\t\tmy_shape = face_utils.shape_to_np(my_shape)\n",
        "\t\t# extract the left and right eye coordinates, then use the\n",
        "\t\t# coordinates to compute the eye aspect ratio for both eyes\n",
        "\t\tleftEye = my_shape[left_eye_start:left_eye_end]\n",
        "\t\trightEye = my_shape[right_eye_start:right_eye_end]\n",
        "\t\tleftEAR = EAR(leftEye)\n",
        "\t\trightEAR = EAR(rightEye)\n",
        "\t\t# average the eye aspect ratio together for both eyes\n",
        "\t\tear_tot = (leftEAR + rightEAR) / 2.0\n",
        "\t\tleftEyeHull = cv.convexHull(leftEye)\n",
        "\t\trightEyeHull = cv.convexHull(rightEye)\n",
        "\t\tcv.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
        "\t\tcv.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
        "\n",
        "\t\tMy_mouth=my_shape[mouth_start: mouth_end]\n",
        "\t\tMy_mouth_MAR=MAR(My_mouth)\n",
        "\t\tcv.drawContours(frame, [My_mouth], -1, (0, 255, 0), 1)\n",
        "\t\n",
        "\t\t#Do the same thing for mouth\n",
        "\n",
        "\t\tif ear_tot < EAR_threshold:\n",
        "\t\t\tCOUNTER += 1\n",
        "\t\t\t# if the eyes were closed for a sufficient number of\n",
        "\t\t\t# then sound the alarm\n",
        "\t\t\tif COUNTER >= frames_threshold:\n",
        "\t\t\t\t# if the alarm is not on, turn it on\n",
        "\t\t\t\tif not alarm_status:\n",
        "\t\t\t\t\talarm_status = True\n",
        "\t\t\t\t\t# check to see if an alarm file was supplied,\n",
        "\t\t\t\t\t# and if so, start a thread to have the alarm\n",
        "\t\t\t\t\t# sound played in the background\n",
        "\t\t\t\t\t#if args[\"alarm\"] != \"\":\n",
        "\t\t\t\t\talarm()\n",
        "\t\t\t\t\tt = Thread(target=alarm)\n",
        "\t\t\t\t\tt.deamon = True\n",
        "\t\t\t\t\tt.start()\n",
        "\t\t\t\t# draw an alarm on the frame\n",
        "\t\t\t\tcv.putText(frame, \"DROWSINESS ALERT!\", (10, 30),cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\t\t# otherwise, the eye aspect ratio is not below the blink\n",
        "\t\t# threshold, so reset the counter and alarm\n",
        "\t\telse:\n",
        "\t\t\tCOUNTER = 0\n",
        "\t\t\talarm_status = False\n",
        "\n",
        "\t\tif My_mouth_MAR>=MAR_threshold:\n",
        "\t\t\tCOUNTER_yawn+=1\n",
        "\t\t\tif COUNTER_yawn>=Mouth_frames_threshold:\n",
        "\t\t\t\tif not alarm_status_yawn:\n",
        "\t\t\t\t\talarm_status_yawn=True\n",
        "\t\t\t\t\talarm()\n",
        "\t\t\t\t\tcv.putText(frame, \"YAWN ALERT!\", (10, 30),cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 3)\n",
        "\t\telse:\n",
        "\t\t\tCOUNTER_yawn=0\n",
        "\t\t\talarm_status_yawn=False\n",
        "\n",
        "\t\tcv.putText(frame, \"EAR: {:.2f}\".format(ear_tot), (300, 30), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\t\tcv.putText(frame, \"MAR: {:.2f}\".format(My_mouth_MAR), (30, 30), cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        " \n",
        "\t# show the frame\n",
        "\tcv.imshow(\"Frame\", frame)\n",
        "\tkey = cv.waitKey(1) & 0xFF\n",
        " \n",
        "\t# if the `q` key was pressed, break from the loop\n",
        "\tif key == ord(\"q\"):\n",
        "\t\tbreak\n",
        "# do a bit of cleanup\n",
        "cv.destroyAllWindows()\n",
        "#vs.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Drowsiness-Detection",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
